# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nEAOD-Z41gX4j34s-UZaA0jDejNx0B0F
"""

!pip install pyserini
!pip install faiss-cpu
!pip install beir

with open('que1.txt', 'r') as f:
    queries = f.readlines()



from pyserini.search.lucene import LuceneSearcher

searcher = LuceneSearcher.from_prebuilt_index('msmarco-v1-passage')

query=queries[3]

hits = searcher.search(query)
rank=[]
docid=[]
sentence_pairs = []
for i in range(0, 10):
    print(f'{i+1:2} {hits[i].docid:7} {hits[i].score:.5f}')
    rank.append(hits[i].score)
    docid.append(hits[i].docid)
    sentence_pairs.append([query,hits[i].raw])
#text= hits[0].raw
print(rank)
print(docid)
#print(text)

#dict=json.loads(text)
#print(dict['contents'])



import json
import numpy as np

!pip install exs



import nltk
nltk.download('punkt')

!pip install typing

from beir.reranking.models import CrossEncoder
model = 'cross-encoder/ms-marco-electra-base'
reranker = CrossEncoder(model)
rerank_scores = reranker.predict(sentence_pairs, batch_size=10)
print(rerank_scores)

r = 0  # explain the top-ranked document.
doc_ids = np.array(docid)
docids_reranked = doc_ids[np.argsort(rerank_scores)[::-1]]  # descending order.
doc_id = docids_reranked[r]
print(doc_id)
type(doc_id)

text=""

for i in range(0,9):
   print(hits[i].docid)
   if(str(hits[i].docid)==(doc_id)):

    text=hits[i].raw
print(text)
dict=json.loads(text)

# Initiliaze EXS, use a svm model to explain...
from newexs import ExplainableSearch
EXS = ExplainableSearch(reranker, 'svm')

exp_input = {}
#exp_input[query] = dict(zip(docid, rank))
exp_input[query]={doc_ids[i] : rerank_scores[i] for i, _ in enumerate(rerank_scores)}
for key, value in exp_input[query].items():
    print(key, value, '\n')
# explain the picked doc, use the 1-th ranked doc as the baseline, use topk-bin method.
# the returned results include {query: (words, weights)}.
exp_doc = {query: {'rank': r,'text':dict['contents']}}
print(exp_doc)
results = EXS.explain(exp_input, exp_doc , 1, 'topk-bin')

import matplotlib.pyplot as plt

def visualize(vocabs:np.array, coef: np.array, show_top: int=10):
        if len(coef.shape) > 1:  # binary,
            coef = np.squeeze(coef)
        sorted_coef = np.sort(coef)
        sorted_idx = np.argsort(coef)
        pos_y = sorted_coef[-show_top:]
        neg_y = sorted_coef[:show_top]
        pos_idx = sorted_idx[-show_top:]
        neg_idx = sorted_idx[:show_top]

        words = np.append(vocabs[pos_idx], vocabs[neg_idx])
        y = np.append(pos_y, neg_y)
        fig, ax = plt.subplots(figsize=(8, 10))
        colors = ['green' if val >0 else 'red' for val in y]
        pos = np.arange(len(y)) + .5
        ax.barh(pos, y, align='center', color=colors)
        ax.set_yticks(np.arange(len(y)))
        ax.set_yticklabels(words, fontsize=18)
        ax.spines['top'].set_visible(False)
        ax.spines['right'].set_visible(False)
        ax.spines['bottom'].set_visible(False)
        ax.spines['left'].set_visible(False)
        ax.set_xticks([])
        #fig.savefig('exs.pdf')
        fig.show()

visualize(results[query][0], results[query][1])